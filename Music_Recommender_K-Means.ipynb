{"cells":[{"cell_type":"markdown","metadata":{},"source":["* `Acousticness:` A numerical variable, a confidence measure from 0.0 to 1.0 indicating whether the track is acoustic. 1.0 represents high confidence that the track is acoustic.\n","\n","* `Danceability:` A numerical variable, danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n","\n","* `Duration_ms:` A numerical variable, the duration of the track in milliseconds.\n","\n","* `Duration_min:` A numerical variable, the duration of the track in minutes.\n","\n","* `Energy:` A numerical variable, energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n","\n","* `Explicit:` A categorical variable, whether the track has explicit lyrics or not (true = yes (1); false = no (0), unknown).\n","\n","* `Id:` The Spotify ID for the track.\n","\n","* `Instrumentalness:` A numerical variable, predicts whether a track does not contain vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater the likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n","\n","* `Key:` A numerical variable, the overall estimated key of the track. Integers map to pitches using standard Pitch Class notation. For example, 0 = C, 1 = C#/Db, 2 = D, and so on. If no key is detected, the value is -1.\n","\n","* `Liveness:` A numerical variable, detects the presence of an audience in the recording. Higher liveness values represent a higher probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n","\n","* `Loudness:` A numerical variable, the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing the relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Typical values range between -60 and 0 db.\n","\n","* `Mode:` A numerical variable, mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n","\n","* `Popularity:` A numerical variable, the popularity of a track is a value between 0 and 100, with 100 being the most popular. Popularity is calculated by algorithm and is based, in large part, on the total number of plays the track has had and how recent those plays are.\n","\n","* `Speechiness:` A numerical variable, speechiness detects the presence of spoken words in a track. The more exclusively spoken the recording (e.g., talk show, audiobook, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including cases such as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n","\n","* `Tempo:` A numerical variable, the overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n","\n","* `Valence:` A numerical variable, a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g., sad, depressed, angry).\n","\n","* `Year:` The year the track was released."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Loading and Initial Analysis\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Load the dataset\n","data = pd.read_csv('https://raw.githubusercontent.com/user/repo/branch/data.csv')\n","\n","# Display the first two rows\n","print(data.head(2))\n","\n","# List unique years in the dataset\n","print(data[\"year\"].unique())\n","\n","# Check the shape of the dataset\n","print(data.shape)\n","\n","# Drop unnecessary columns\n","data = data.drop([\"explicit\", \"key\", \"mode\"], axis=1)\n","\n","# Check the shape of the dataset after dropping columns\n","print(data.shape)\n","\n","# Check for missing values\n","print(data.isna().sum())\n","\n","#Data Visualization\n","\n","import plotly.express as px\n","\n","# Example of a line plot with Plotly Express\n","fig = px.line(data, x=\"year\", y=\"loudness\", title=\"Loudness Over Years\")\n","fig.show()\n","\n","import plotly.graph_objects as go\n","\n","# Example of creating a figure with Plotly Graph Objects\n","fig = go.Figure()\n","# Here, you would add traces or layout adjustments as needed\n","fig.show()\n","\n","#Applying K-Means Clustering\n","\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","\n","# Create a K-Means clustering pipeline with PCA\n","clustering_pipeline = Pipeline([\n","    ('pca', PCA(n_components=2)),\n","    ('kmeans', KMeans(n_clusters=5, random_state=42))\n","])\n","\n","# Fit the pipeline to the data\n","clustering_pipeline.fit(data)\n","\n","# Example of using the pipeline to predict clusters\n","clusters = clustering_pipeline.predict(data)\n","\n","\n","#Spotify API and Spotipy Library\n","!pip install spotipy\n","import spotipy\n","from spotipy.oauth2 import SpotifyClientCredentials\n","\n","# Set up Spotipy client credentials\n","client_credentials_manager = SpotifyClientCredentials(client_id='YOUR_CLIENT_ID', client_secret='YOUR_CLIENT_SECRET')\n","sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n","\n","# Recommendation Function and Visualization\n","\n","def recommend_song(song_name):\n","    # Here you would define the logic to recommend a song based on the input song name\n","    # This could involve querying the Spotify API, performing clustering analysis, etc.\n","    pass\n","\n","# Example usage of the recommendation function\n","recommend_song('Ed Sheeran - Shape of You')"]}],"metadata":{"colab":{"collapsed_sections":["Cf0u9LxLwkRq","R8Cj61yTOH44","tl2upg8t__25","C_jPt0TF3WRT"],"name":"Aula 5.3 - Recomendador_de_musicas.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
